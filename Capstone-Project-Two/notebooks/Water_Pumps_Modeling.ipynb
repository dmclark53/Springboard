{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "limited-pioneer",
   "metadata": {},
   "source": [
    "# Water Pumps: Modeling\n",
    "## Business Problem:\n",
    "Tanzania is a developing country and access to water is very important for the health of the population. For this reason, it is vital that all water pumps are properly working. Currently, the only way to monitor pump working status is by physically visiting the site. This is time consuming and costly. Therefore, a more intelligent solution to monitor water pump status is desirable.\n",
    "\n",
    "This project will address the following question: How can the government of Tanzania improve water pump maintenance by knowing the pump functional status in advance?\n",
    "\n",
    "**Goal:** The client would like to err on the side of predicting a pump is failing, when in fact it is functional. This means, reducing type two error for _non-functional_ and _functional needs repair_ classes. Therefore, the modeling strategy will focus on improving the recall metric, especially related to these two classes.\n",
    "    \n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "competent-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-plant",
   "metadata": {},
   "source": [
    "## Load Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "limited-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test():\n",
    "    file_list = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "    data_sets = []\n",
    "    for filename in file_list:\n",
    "        data_sets.append(pickle.load(open(f'../data/clean/{filename}', 'rb')))\n",
    "    return tuple(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessible-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "synthetic-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21296, 230)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-cookbook",
   "metadata": {},
   "source": [
    "Load predictions from baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "present-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_base = pickle.load(open(f'../data/clean/y_test_base', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floppy-companion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9127,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-cleaner",
   "metadata": {},
   "source": [
    "## Rescaling\n",
    "Rescale the features to values between 0 and 1. Since the categorical variables are one-hot-encoded, this will ensure that the continuous variables are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hollywood-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_rescaled = scaler.transform(X_train)\n",
    "X_test_rescaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indoor-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rescaled.min(), X_train_rescaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "higher-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.388478523218112e-06, 1.0018616381450016)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_rescaled.min(), X_test_rescaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "realistic-cowboy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21296, 230), (9127, 230))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rescaled.shape, X_test_rescaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-shuttle",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "Counter the class imbalanced data set by performing resampling. I will consider both over sampling and under sampling.\n",
    "\n",
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demanding-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, y_train_over = SMOTE().fit_resample(X_train_rescaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "announced-citation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional                 12482\n",
      "functional needs repair    12482\n",
      "non functional             12482\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-population",
   "metadata": {},
   "source": [
    "### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "instrumental-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under, y_train_under = RandomUnderSampler(random_state=42).fit_resample(X_train_rescaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "domestic-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non functional             1505\n",
      "functional needs repair    1505\n",
      "functional                 1505\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_train_under).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-greek",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "I will create two sets of models, one for over sampled training sets, and another for under sampled training sets. For each set of models, I will consider the following models:\n",
    "* Logistic Regression.\n",
    "* Random Forrest.\n",
    "* XGBoost.\n",
    "\n",
    "### Models with Over Sampling\n",
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adequate-picture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', solver='saga')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_over = LogisticRegression(solver='saga', multi_class='multinomial')\n",
    "logreg_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hungry-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_logreg_over = logreg_over.predict(X_train_over)\n",
    "y_pred_logreg_over = logreg_over.predict(X_test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adopted-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.69      0.67      0.68     12482\n",
      "functional needs repair       0.69      0.77      0.73     12482\n",
      "         non functional       0.74      0.69      0.72     12482\n",
      "\n",
      "               accuracy                           0.71     37446\n",
      "              macro avg       0.71      0.71      0.71     37446\n",
      "           weighted avg       0.71      0.71      0.71     37446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_over, y_pred_train_logreg_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stock-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.85      0.66      0.74      5349\n",
      "functional needs repair       0.23      0.73      0.35       645\n",
      "         non functional       0.73      0.68      0.70      3133\n",
      "\n",
      "               accuracy                           0.67      9127\n",
      "              macro avg       0.60      0.69      0.60      9127\n",
      "           weighted avg       0.76      0.67      0.70      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-karma",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "The roughly 5% drop in performance between the training and test scores indicates that over fitting could be a problem. I will try to address this using cross-validation. I will also use a grid search to identify the best regularization parameter, which could reduce the over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "seven-chest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(max_iter=10000,\n",
       "                                                multi_class='multinomial',\n",
       "                                                solver='saga'),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'C': array([0.2, 0.6, 1. , 1.4, 1.8, 2.2]),\n",
       "                                        'penalty': ['l1', 'l2']},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_over_rs = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=10000)\n",
    "rs_logreg_params = {'C': np.arange(0.2, 2.4, 0.4), 'penalty': ['l1', 'l2']}\n",
    "rs_logreg = RandomizedSearchCV(logreg_over_rs, rs_logreg_params, random_state=42, n_jobs=-1)\n",
    "rs_logreg.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intended-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value for C is 2.200.\n",
      "The best penalty is l2.\n"
     ]
    }
   ],
   "source": [
    "best_C = rs_logreg.best_estimator_.get_params()['C']\n",
    "best_penalty = rs_logreg.best_estimator_.get_params()['penalty']\n",
    "print(f'The best value for C is {best_C:0.3f}.')\n",
    "print(f'The best penalty is {best_penalty}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "visible-disclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.2000000000000006, max_iter=10000,\n",
       "                   multi_class='multinomial', solver='saga')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_over_2 = LogisticRegression(solver='saga', multi_class='multinomial', C=best_C, penalty=best_penalty, max_iter=10000)\n",
    "logreg_over_2.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "powerful-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_logreg_over_2 = logreg_over_2.predict(X_train_over)\n",
    "y_pred_logreg_over_2 = logreg_over_2.predict(X_test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exciting-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.69      0.67      0.68     12482\n",
      "functional needs repair       0.69      0.77      0.73     12482\n",
      "         non functional       0.74      0.69      0.72     12482\n",
      "\n",
      "               accuracy                           0.71     37446\n",
      "              macro avg       0.71      0.71      0.71     37446\n",
      "           weighted avg       0.71      0.71      0.71     37446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_over, y_pred_train_logreg_over_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "engaging-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.85      0.66      0.74      5349\n",
      "functional needs repair       0.23      0.73      0.35       645\n",
      "         non functional       0.73      0.68      0.70      3133\n",
      "\n",
      "               accuracy                           0.67      9127\n",
      "              macro avg       0.60      0.69      0.60      9127\n",
      "           weighted avg       0.76      0.67      0.70      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg_over_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-eclipse",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "After searching for better parameters using a randomized search, I do not see an improvement in the recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-hollywood",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "important-expense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_over = RandomForestClassifier(n_estimators=100, random_state = 42, n_jobs=-1)\n",
    "rf_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cleared-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_over = rf_over.predict(X_test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "controlled-event",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.83      0.86      0.85      5349\n",
      "functional needs repair       0.46      0.42      0.44       645\n",
      "         non functional       0.81      0.77      0.78      3133\n",
      "\n",
      "               accuracy                           0.80      9127\n",
      "              macro avg       0.70      0.68      0.69      9127\n",
      "           weighted avg       0.79      0.80      0.80      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-median",
   "metadata": {},
   "source": [
    "**Observations:** Without doing any hyperparameter tuning, we can see mixed results as compared with the logistic regression model. The minority class shows an improvement in precision, but a decrease in recall. On the otherhand, the majority class shows an improvement in recall for the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "invalid-shell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_over_2 = RandomForestClassifier(n_estimators=100, random_state = 42, max_features='sqrt', n_jobs=-1)\n",
    "rf_over_2.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "confused-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_over_2 = rf_over_2.predict(X_test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sufficient-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.83      0.86      0.85      5349\n",
      "functional needs repair       0.46      0.42      0.44       645\n",
      "         non functional       0.81      0.77      0.78      3133\n",
      "\n",
      "               accuracy                           0.80      9127\n",
      "              macro avg       0.70      0.68      0.69      9127\n",
      "           weighted avg       0.79      0.80      0.80      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf_over_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "first-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_over_3 = RandomForestClassifier(n_estimators=100, random_state = 42, max_features='sqrt', max_depth=None, min_samples_split=2, n_jobs=-1)\n",
    "rf_over_3.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "synthetic-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_over_3 = rf_over_3.predict(X_test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "intensive-grill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.83      0.86      0.85      5349\n",
      "functional needs repair       0.46      0.42      0.44       645\n",
      "         non functional       0.81      0.77      0.78      3133\n",
      "\n",
      "               accuracy                           0.80      9127\n",
      "              macro avg       0.70      0.68      0.69      9127\n",
      "           weighted avg       0.79      0.80      0.80      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf_over_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-vacation",
   "metadata": {},
   "source": [
    "**Observations:** After adjusting the parameters using the [suggestions](https://scikit-learn.org/stable/modules/ensemble.html#random-forest-parameters) from scikit-learn, there is still not an improvement in recall for the minority classes. I will need to do a grid search with cross validation to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ruled-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_over_rs = RandomForestClassifier(random_state = 42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "junior-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = list(np.arange(10, 110, 10))\n",
    "max_depth_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "negative-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_params_rf_over = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': max_depth_list,\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': list(np.arange(1, 11, 1)),\n",
    "    'min_samples_split': list(np.arange(1, 11, 1)),\n",
    "    'n_estimators': list(np.arange(200, 2200, 200))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "native-bloom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10],\n",
       "                                        'min_samples_split': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf_over = RandomizedSearchCV(rf_over_rs, rs_params_rf_over, random_state=42, n_jobs=-1)\n",
    "rs_rf_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "initial-stupid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf_over.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "prospective-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=90, min_samples_split=3, n_estimators=1600,\n",
       "                       n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_over_4 = RandomForestClassifier(n_estimators=1600, \n",
    "                                   random_state = 42, \n",
    "                                   max_features='auto', \n",
    "                                   max_depth=90, \n",
    "                                   min_samples_split=3, \n",
    "                                   min_samples_leaf=1,\n",
    "                                   bootstrap=True,\n",
    "                                   n_jobs=-1)\n",
    "rf_over_4.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "representative-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_over_4 = rf_over_4.predict(X_test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "split-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.84      0.87      0.85      5349\n",
      "functional needs repair       0.46      0.41      0.44       645\n",
      "         non functional       0.81      0.78      0.80      3133\n",
      "\n",
      "               accuracy                           0.80      9127\n",
      "              macro avg       0.70      0.69      0.69      9127\n",
      "           weighted avg       0.80      0.80      0.80      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf_over_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-beginning",
   "metadata": {},
   "source": [
    "**Observations:** I do not see any large improvement in metrics, recall nor precision, after tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
