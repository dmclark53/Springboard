{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-substitute",
   "metadata": {},
   "source": [
    "# Water Pumps: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bearing-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-country",
   "metadata": {},
   "source": [
    "## Load Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advanced-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test():\n",
    "    file_list = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "    data_sets = []\n",
    "    for filename in file_list:\n",
    "        data_sets.append(pickle.load(open(f'../data/clean/{filename}', 'rb')))\n",
    "    return tuple(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "massive-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "substantial-booth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21296, 230)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-glucose",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "Counter the class imbalanced data set by performing resampling. I will consider both over sampling and under sampling.\n",
    "\n",
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lesbian-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, y_train_over = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "genetic-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non functional             12482\n",
      "functional needs repair    12482\n",
      "functional                 12482\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-kenya",
   "metadata": {},
   "source": [
    "### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "express-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under, y_train_under = RandomUnderSampler(random_state=42).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "delayed-wright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non functional             1505\n",
      "functional                 1505\n",
      "functional needs repair    1505\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_train_under).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-advantage",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "I will create two sets of models, one for over sampled training sets, and another for under sampled training sets. For each set of models, I will consider the following models:\n",
    "* Logistic Regression.\n",
    "* Random Forrest.\n",
    "* XGBoost.\n",
    "\n",
    "### Models with Over Sampling\n",
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "considerable-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is: 71.890%.\n",
      "The test score is: 67.196%.\n"
     ]
    }
   ],
   "source": [
    "params_logreg_over = [('min_max', MinMaxScaler()), ('log_reg', LogisticRegression(solver='saga', multi_class='multinomial'))]\n",
    "pipe_logreg_over = Pipeline(params_logreg_over)\n",
    "pipe_logreg_over.fit(X_train_over, y_train_over)\n",
    "print(f'The training score is: {pipe_logreg_over.score(X_train_over, y_train_over):0.3%}.')\n",
    "print(f'The test score is: {pipe_logreg_over.score(X_test, y_test):0.3%}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unexpected-creature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter is 1.000.\n"
     ]
    }
   ],
   "source": [
    "C = pipe_logreg_over.get_params()['log_reg__C']\n",
    "print(f'The regularization parameter is {C:0.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-symposium",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "The roughly 5% drop in performance between the training and test scores indicates that over fitting could be a problem. I will try to address this using cross-validation. I will also use a grid search to identify the best regularization parameter, which could reduce the over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "collect-buyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value for C is 10.000.\n"
     ]
    }
   ],
   "source": [
    "params_logreg_over_gs = [('min_max', MinMaxScaler()), ('log_reg', LogisticRegression(solver='saga', multi_class='multinomial', max_iter=10000))]\n",
    "pipe_logreg_over_gs = Pipeline(params_logreg_over_gs)\n",
    "gs_logreg_params = {'log_reg__C': np.logspace(-1, 1, num=5)}\n",
    "gs_logreg = GridSearchCV(pipe_logreg_over_gs, gs_logreg_params, n_jobs=-1)\n",
    "gs_logreg.fit(X_train_over, y_train_over)\n",
    "best_c = gs_logreg.best_estimator_.get_params()['log_reg__C']\n",
    "print(f'The best value for C is {best_c:0.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "compliant-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is: 71.936%.\n",
      "The test score is: 67.240%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "params_logreg_over = [('min_max', MinMaxScaler()), ('log_reg', LogisticRegression(solver='saga', multi_class='multinomial', C=best_c))]\n",
    "pipe_logreg_over = Pipeline(params_logreg_over)\n",
    "pipe_logreg_over.fit(X_train_over, y_train_over)\n",
    "print(f'The training score is: {pipe_logreg_over.score(X_train_over, y_train_over):0.3%}.')\n",
    "print(f'The test score is: {pipe_logreg_over.score(X_test, y_test):0.3%}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-medicaid",
   "metadata": {},
   "source": [
    "**Observations:** The grid search found a regularization parameter that gave a better accuracy, but did not improve overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accepted-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_logreg_over = pipe_logreg_over.predict(X_train_over)\n",
    "y_pred_logreg_over = pipe_logreg_over.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collective-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.69      0.67      0.68     12482\n",
      "functional needs repair       0.71      0.78      0.74     12482\n",
      "         non functional       0.76      0.71      0.73     12482\n",
      "\n",
      "               accuracy                           0.72     37446\n",
      "              macro avg       0.72      0.72      0.72     37446\n",
      "           weighted avg       0.72      0.72      0.72     37446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_over, y_pred_train_logreg_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "foreign-declaration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.84      0.67      0.74      5349\n",
      "functional needs repair       0.22      0.70      0.34       645\n",
      "         non functional       0.74      0.68      0.71      3133\n",
      "\n",
      "               accuracy                           0.67      9127\n",
      "              macro avg       0.60      0.68      0.60      9127\n",
      "           weighted avg       0.76      0.67      0.70      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-hollywood",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "The recall value is pretty mediocre across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-israeli",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monetary-threat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is: 99.997%.\n",
      "The test score is: 80.607%.\n"
     ]
    }
   ],
   "source": [
    "params_rf_over = [('min_max', MinMaxScaler()), ('random_forest', RandomForestClassifier(n_estimators=100, random_state = 42, n_jobs=-1))]\n",
    "pipe_rf_over = Pipeline(params_rf_over)\n",
    "pipe_rf_over.fit(X_train_over, y_train_over)\n",
    "print(f'The training score is: {pipe_rf_over.score(X_train_over, y_train_over):0.3%}.')\n",
    "print(f'The test score is: {pipe_rf_over.score(X_test, y_test):0.3%}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-virgin",
   "metadata": {},
   "source": [
    "**Observations:** Without doing any hyperparameter tuning, this model overfit a lot on the first try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "covered-exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is: 99.997%.\n",
      "The test score is: 80.607%.\n"
     ]
    }
   ],
   "source": [
    "params_rf_over = [('min_max', MinMaxScaler()), ('random_forest', RandomForestClassifier(n_estimators=100, \n",
    "                                                                                        random_state = 42, \n",
    "                                                                                        max_features='sqrt', \n",
    "                                                                                        n_jobs=-1))]\n",
    "pipe_rf_over = Pipeline(params_rf_over)\n",
    "pipe_rf_over.fit(X_train_over, y_train_over)\n",
    "print(f'The training score is: {pipe_rf_over.score(X_train_over, y_train_over):0.3%}.')\n",
    "print(f'The test score is: {pipe_rf_over.score(X_test, y_test):0.3%}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "severe-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is: 99.997%.\n",
      "The test score is: 80.607%.\n"
     ]
    }
   ],
   "source": [
    "params_rf_over = [('min_max', MinMaxScaler()), ('random_forest', RandomForestClassifier(n_estimators=100, \n",
    "                                                                                        random_state = 42, \n",
    "                                                                                        max_features='sqrt', \n",
    "                                                                                        max_depth=None, \n",
    "                                                                                        min_samples_split=2,\n",
    "                                                                                        n_jobs=-1))]\n",
    "pipe_rf_over = Pipeline(params_rf_over)\n",
    "pipe_rf_over.fit(X_train_over, y_train_over)\n",
    "print(f'The training score is: {pipe_rf_over.score(X_train_over, y_train_over):0.3%}.')\n",
    "print(f'The test score is: {pipe_rf_over.score(X_test, y_test):0.3%}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-daisy",
   "metadata": {},
   "source": [
    "**Observations:** After adjusting the parameters using the [suggestions](https://scikit-learn.org/stable/modules/ensemble.html#random-forest-parameters) from scikit-learn, there is still a lot of overfitting. I will need to do a grid search with cross validation to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "controversial-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf_over = [('min_max', MinMaxScaler()), ('rf', RandomForestClassifier(random_state = 42, n_jobs=-1))]\n",
    "pipe_rf_over = Pipeline(params_rf_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "loose-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = list(np.arange(10, 110, 10))\n",
    "max_depth_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sophisticated-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_params_rf_over = {\n",
    "    'rf__bootstrap': [True, False],\n",
    "    'rf__max_depth': max_depth_list,\n",
    "    'rf__max_features': ['auto', 'sqrt'],\n",
    "    'rf__min_samples_leaf': list(np.arange(1, 11, 1)),\n",
    "    'rf__min_samples_split': list(np.arange(1, 11, 1)),\n",
    "    'rf__n_estimators': list(np.arange(200, 2200, 200))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "oriental-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'verbose',\n",
       " 'min_max',\n",
       " 'rf',\n",
       " 'min_max__clip',\n",
       " 'min_max__copy',\n",
       " 'min_max__feature_range',\n",
       " 'rf__bootstrap',\n",
       " 'rf__ccp_alpha',\n",
       " 'rf__class_weight',\n",
       " 'rf__criterion',\n",
       " 'rf__max_depth',\n",
       " 'rf__max_features',\n",
       " 'rf__max_leaf_nodes',\n",
       " 'rf__max_samples',\n",
       " 'rf__min_impurity_decrease',\n",
       " 'rf__min_impurity_split',\n",
       " 'rf__min_samples_leaf',\n",
       " 'rf__min_samples_split',\n",
       " 'rf__min_weight_fraction_leaf',\n",
       " 'rf__n_estimators',\n",
       " 'rf__n_jobs',\n",
       " 'rf__oob_score',\n",
       " 'rf__random_state',\n",
       " 'rf__verbose',\n",
       " 'rf__warm_start']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipe_rf_over.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "human-hospital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('min_max', MinMaxScaler()),\n",
       "                                             ('rf',\n",
       "                                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                                     random_state=42))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'rf__bootstrap': [True, False],\n",
       "                                        'rf__max_depth': [10, 20, 30, 40, 50,\n",
       "                                                          60, 70, 80, 90, 100,\n",
       "                                                          None],\n",
       "                                        'rf__max_features': ['auto', 'sqrt'],\n",
       "                                        'rf__min_samples_leaf': [1, 2, 3, 4, 5,\n",
       "                                                                 6, 7, 8, 9,\n",
       "                                                                 10],\n",
       "                                        'rf__min_samples_split': [1, 2, 3, 4, 5,\n",
       "                                                                  6, 7, 8, 9,\n",
       "                                                                  10],\n",
       "                                        'rf__n_estimators': [200, 400, 600, 800,\n",
       "                                                             1000, 1200, 1400,\n",
       "                                                             1600, 1800,\n",
       "                                                             2000]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf_over = RandomizedSearchCV(pipe_rf_over, rs_params_rf_over, random_state=42, n_jobs=-1)\n",
    "rs_rf_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "coupled-treasury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__n_estimators': 800,\n",
       " 'rf__min_samples_split': 3,\n",
       " 'rf__min_samples_leaf': 1,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__max_depth': 90,\n",
       " 'rf__bootstrap': True}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf_over.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "suffering-acoustic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 150, 200, 250, 300])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(100, 350, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "uniform-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_params_rf_over = {\n",
    "    'rf__bootstrap': [False],\n",
    "    'rf__max_depth': list(np.arange(90, 115, 5)),\n",
    "    'rf__max_features': ['auto', 'sqrt'],\n",
    "    'rf__min_samples_leaf': list(np.arange(1, 5, 1)),\n",
    "    'rf__min_samples_split': list(np.arange(8, 13, 1)),\n",
    "    'rf__n_estimators': list(np.arange(100, 350, 50))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "painful-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_rf_over = GridSearchCV(pipe_rf_over, gs_params_rf_over, n_jobs=-1)\n",
    "# gs_rf_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "naughty-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is: 97.749%.\n",
      "The test score is: 81.221%.\n"
     ]
    }
   ],
   "source": [
    "params_rf_over = [('min_max', MinMaxScaler()), ('random_forest', RandomForestClassifier(n_estimators=800, \n",
    "                                                                                        random_state = 42, \n",
    "                                                                                        max_features='sqrt', \n",
    "                                                                                        max_depth=100, \n",
    "                                                                                        min_samples_split=10,\n",
    "                                                                                        min_samples_leaf=1,\n",
    "                                                                                        bootstrap=False,\n",
    "                                                                                        n_jobs=-1))]\n",
    "pipe_rf_over = Pipeline(params_rf_over)\n",
    "pipe_rf_over.fit(X_train_over, y_train_over)\n",
    "print(f'The training score is: {pipe_rf_over.score(X_train_over, y_train_over):0.3%}.')\n",
    "print(f'The test score is: {pipe_rf_over.score(X_test, y_test):0.3%}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "active-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_rf_over = pipe_rf_over.predict(X_train_over)\n",
    "y_pred_rf_over = pipe_rf_over.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stuffed-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.95      0.99      0.97     12482\n",
      "functional needs repair       0.99      0.98      0.99     12482\n",
      "         non functional       0.99      0.97      0.98     12482\n",
      "\n",
      "               accuracy                           0.98     37446\n",
      "              macro avg       0.98      0.98      0.98     37446\n",
      "           weighted avg       0.98      0.98      0.98     37446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_over, y_pred_train_rf_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "prospective-thursday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.90      0.86      5349\n",
      "functional needs repair       0.56      0.33      0.42       645\n",
      "         non functional       0.83      0.76      0.79      3133\n",
      "\n",
      "               accuracy                           0.81      9127\n",
      "              macro avg       0.73      0.67      0.69      9127\n",
      "           weighted avg       0.80      0.81      0.81      9127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf_over))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
