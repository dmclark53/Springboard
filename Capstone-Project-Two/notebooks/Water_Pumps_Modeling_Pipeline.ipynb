{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "needed-model",
   "metadata": {},
   "source": [
    "# Water Pumps - Modeling Pipeline\n",
    "\n",
    "In this notebook, I will take what I learned in the Modeling notebook to create a pipeline that fits all three models. The notebook can be configured to either over sample or under sample the data. For each model, hyperparameter tuning will be performed, using the strategy developed in the Modeling notebook. The best parameters will then be selected for the final model for each model type. All results are saved to a csv file. At the end of the notebook, the results between each model can be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-psychology",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "municipal-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-helen",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "Set up configurations for current run of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breeding-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = True\n",
    "debug = True\n",
    "# sampling_type = 'over'\n",
    "sampling_type = 'under'\n",
    "results_filename = 'pipeline_results.csv'\n",
    "if binary:\n",
    "    split_filename = results_filename.split('_')\n",
    "    results_filename = '_'.join([split_filename[0], 'binary', split_filename[1]])\n",
    "results_filepath = f'../results/{results_filename}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-audio",
   "metadata": {},
   "source": [
    "## Load Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weekly-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test():\n",
    "    file_list = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "    data_sets = []\n",
    "    for filename in file_list:\n",
    "        data_sets.append(pickle.load(open(f'../data/clean/{filename}', 'rb')))\n",
    "    return tuple(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "palestinian-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "through-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this block to shortening training data for debugging.\n",
    "if debug:\n",
    "    row_cut = 100\n",
    "    X_train = X_train[:100]\n",
    "    y_train = y_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-joseph",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "Load predictions from baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "secondary-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base = pickle.load(open(f'../data/clean/y_pred_base', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-cologne",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "studied-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_train, X_test, y_train, y_test, sampling_type):\n",
    "    \n",
    "    if binary:\n",
    "        y_train = pd.Series(y_train).replace({'functional needs repair': 'faulty', 'non functional': 'faulty'}).values\n",
    "        y_test = pd.Series(y_test).replace({'functional needs repair': 'faulty', 'non functional': 'faulty'}).values\n",
    "    \n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_rescaled = scaler.transform(X_train)\n",
    "    X_test_pipe = scaler.transform(X_test)\n",
    "    \n",
    "    if sampling_type == 'over':\n",
    "        X_train_pipe, y_train_pipe = SMOTE().fit_resample(X_train_rescaled, y_train)\n",
    "    elif sampling_type == 'under':\n",
    "        X_train_pipe, y_train_pipe = RandomUnderSampler(random_state=42).fit_resample(X_train_rescaled, y_train)\n",
    "    else:\n",
    "        raise Exception(\"sampling_type must be 'over' or 'under'. Please try again.\")\n",
    "    \n",
    "    y_test_pipe = y_test\n",
    "    \n",
    "    return X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "federal-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = prepare_data(X_train, X_test, y_train, y_test, sampling_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-workstation",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-recorder",
   "metadata": {},
   "source": [
    "### Load Saved Results\n",
    "If a results file exists, load it, otherwise set it to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sporting-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(results_filepath):\n",
    "    df_results = pd.read_csv(results_filepath, index_col=0, header=[0, 1])\n",
    "    df_results.drop('class count', level=1, axis=1, inplace=True)\n",
    "else:\n",
    "    df_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indie-wagner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_under</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>faulty</th>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.567761</td>\n",
       "      <td>0.511430</td>\n",
       "      <td>0.621758</td>\n",
       "      <td>0.569132</td>\n",
       "      <td>0.515352</td>\n",
       "      <td>0.530914</td>\n",
       "      <td>0.588671</td>\n",
       "      <td>0.514713</td>\n",
       "      <td>0.546321</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>0.547380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.677973</td>\n",
       "      <td>0.642737</td>\n",
       "      <td>0.684826</td>\n",
       "      <td>0.580482</td>\n",
       "      <td>0.679110</td>\n",
       "      <td>0.724434</td>\n",
       "      <td>0.685298</td>\n",
       "      <td>0.632642</td>\n",
       "      <td>0.665038</td>\n",
       "      <td>0.636194</td>\n",
       "      <td>0.666146</td>\n",
       "      <td>0.637876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logreg_over           logreg_under             rf_over            \\\n",
       "             precision    recall    precision    recall precision    recall   \n",
       "faulty        0.528846  0.567761     0.511430  0.621758  0.569132  0.515352   \n",
       "functional    0.677973  0.642737     0.684826  0.580482  0.679110  0.724434   \n",
       "\n",
       "            rf_under            xgb_over           xgb_under            \n",
       "           precision    recall precision    recall precision    recall  \n",
       "faulty      0.530914  0.588671  0.514713  0.546321  0.516355  0.547380  \n",
       "functional  0.685298  0.632642  0.665038  0.636194  0.666146  0.637876  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "verbal-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(y_test, y_pred, model_type, df=None):\n",
    "    \n",
    "    if df is not None:\n",
    "        if model_type in df.columns:\n",
    "            df.drop(model_type, level=0, axis=1, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    results = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    df_results.drop(columns=['f1-score', 'support'], inplace=True)\n",
    "    df_results.drop(['accuracy', 'macro avg', 'weighted avg'], inplace=True)\n",
    "    \n",
    "    multi_columns = [(model_type, x) for x in df_results.columns]\n",
    "    df_results.columns = pd.MultiIndex.from_tuples(multi_columns)\n",
    "    \n",
    "    if df is None:\n",
    "        return df_results\n",
    "    else:\n",
    "        df_results = pd.concat([df, df_results], axis=1)\n",
    "        df_results.sort_index(axis=1, level=0, inplace=True)\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-appreciation",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "Set up baseline model results and store in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "committed-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'base_line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "educational-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary == False:\n",
    "    df_results = store_results(y_test, y_pred_base, model_type, df=df_results)\n",
    "    df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-shooting",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "composite-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'logreg_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_rs = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=10000)\n",
    "rs_logreg_params = {'C': np.arange(0.2, 2.4, 0.4), 'penalty': ['l1', 'l2']}\n",
    "rs_logreg = RandomizedSearchCV(logreg_rs, rs_logreg_params, random_state=42, n_jobs=-1)\n",
    "rs_logreg.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_params(best_params):\n",
    "    for key, value in best_params.items():\n",
    "        if type(best_params[key]) == str:\n",
    "            print(f' * {key}: {best_params[key]}')\n",
    "        else:\n",
    "            print(f' * {key}: {best_params[key]:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best hyperparameters of logistic regression are:')\n",
    "print_best_params(rs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyper_params(model_type, sampling, binary, best_params):\n",
    "    \n",
    "    next_row = {\n",
    "        'sampling': sampling,\n",
    "        'num_classes': 3 - int(True == binary),\n",
    "    }\n",
    "    \n",
    "    for key, value in best_params.items():\n",
    "        next_row[key] = best_params[key]\n",
    "    \n",
    "    hyper_params_files = f'../results/{model_type}_hyperparams.csv'\n",
    "    if os.path.isfile(hyper_params_files):\n",
    "        df = pd.read_csv(hyper_params_files)\n",
    "        next_index = len(df)\n",
    "        df.loc[next_index] = next_row\n",
    "        df.drop_duplicates(subset=['sampling', 'num_classes'], ignore_index=True, inplace=True)\n",
    "    else:\n",
    "        df = pd.DataFrame(next_row, index=[0])\n",
    "    df.to_csv(hyper_params_files, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logreg_params = save_hyper_params('logreg', sampling_type, binary, rs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logreg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_best = LogisticRegression(\n",
    "    solver='saga', \n",
    "    multi_class='multinomial', \n",
    "    C=rs_logreg.best_params_['C'], \n",
    "    penalty=rs_logreg.best_params_['penalty'], \n",
    "    max_iter=10000\n",
    ")\n",
    "logreg_best.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg_best = logreg_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = store_results(y_test_pipe, y_pred_logreg_best, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-therapy",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'rf_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs = RandomForestClassifier(random_state = 42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = list(np.arange(10, 110, 10))\n",
    "max_depth_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf_params = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': max_depth_list,\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': list(np.arange(1, 11, 1)),\n",
    "    'min_samples_split': list(np.arange(1, 11, 1)),\n",
    "    'n_estimators': list(np.arange(200, 2200, 200))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf = RandomizedSearchCV(rf_rs, rs_rf_params, random_state=42, n_jobs=-1)\n",
    "rs_rf.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best hyperparameters for random forest are:')\n",
    "print_best_params(rs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-performance",
   "metadata": {},
   "source": [
    "Double the number of trees for the final random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf.best_params_['n_estimators'] *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_params = save_hyper_params('rf', sampling_type, binary, rs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators = rs_rf.best_params_['n_estimators'],\n",
    "    min_samples_split = rs_rf.best_params_['min_samples_split'],\n",
    "    min_samples_leaf = rs_rf.best_params_['min_samples_leaf'],\n",
    "    max_features = rs_rf.best_params_['max_features'],\n",
    "    max_depth = rs_rf.best_params_['max_depth'],\n",
    "    bootstrap = rs_rf.best_params_['bootstrap'],\n",
    "    random_state = 42, \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = store_results(y_test_pipe, y_pred_rf, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-transsexual",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'xgb_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary:\n",
    "    class_mapping = {\n",
    "        'functional': 0,\n",
    "        'faulty': 1\n",
    "    }\n",
    "else:\n",
    "    class_mapping = {\n",
    "        'functional': 0,\n",
    "        'functional needs repair': 1,\n",
    "        'non functional': 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = pd.Series(y_train_pipe).replace(class_mapping).values\n",
    "y_test_encoded = pd.Series(y_test_pipe).replace(class_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rs = XGBClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    rs_params_xgb_over = {\n",
    "        'max_depth': [1],\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0]\n",
    "    }\n",
    "else:\n",
    "    rs_params_xgb_over = {\n",
    "        'max_depth': list(np.arange(1, 7, 2)),\n",
    "        'min_child_weight': list(np.arange(1, 7, 2)),\n",
    "        'gamma': [0, 1, 5]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_xgb = RandomizedSearchCV(xgb_rs, rs_params_xgb_over, random_state=42, n_jobs=-1, n_iter=100)\n",
    "rs_xgb.fit(X_train_pipe, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best parameters for XGBoost are:')\n",
    "print_best_params(rs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-outside",
   "metadata": {},
   "source": [
    "Set the total number of trees to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_xgb.best_params_['n_estimators'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_params = save_hyper_params('xgb', sampling_type, binary, rs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = XGBClassifier(\n",
    "    n_estimators=rs_xgb.best_params_['n_estimators'],\n",
    "    max_depth=rs_xgb.best_params_['max_depth'],\n",
    "    min_child_weight=rs_xgb.best_params_['min_child_weight'],\n",
    "    gamma=rs_xgb.best_params_['gamma']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best.fit(X_train_pipe, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = xgb_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = {}\n",
    "if binary:\n",
    "    reverse_mapping = {\n",
    "        0:'functional',\n",
    "        1:'faulty'\n",
    "    }\n",
    "else:\n",
    "    reverse_mapping = {\n",
    "        0:'functional',\n",
    "        1:'functional needs repair',\n",
    "        2:'non functional'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = pd.Series(y_pred_encoded).replace(reverse_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = store_results(y_test_pipe, y_pred_xgb, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-coordinator",
   "metadata": {},
   "source": [
    "### Add Class Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_class_counts(df, y_test):\n",
    "    df_class_counts = pd.DataFrame(pd.Series(y_test).value_counts())\n",
    "    df_class_counts.columns = pd.MultiIndex.from_tuples([('', 'class count')])\n",
    "    df_results = pd.concat([df, df_class_counts], axis=1)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = add_class_counts(df_results, y_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-mayor",
   "metadata": {},
   "source": [
    "### Save Results\n",
    "Save the results from the pipeline to the results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(results_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-variable",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(get_binary=False):\n",
    "    results_filename = 'pipeline_results.csv'\n",
    "    if get_binary:\n",
    "        split_filename = results_filename.split('_')\n",
    "        results_filename = '_'.join([split_filename[0], 'binary', split_filename[1]])\n",
    "    results_filepath = f'../results/{results_filename}'\n",
    "    if os.path.isfile(results_filepath):\n",
    "        df = pd.read_csv(results_filepath, index_col=0, header=[0, 1])\n",
    "        unnnamed = [x[0] for x in df.columns if 'Unnamed' in x[0]][0]\n",
    "        new_index = [(x[0].replace(unnnamed, ' '), x[1]) if unnnamed in x else x for x in df.columns.values.tolist()]\n",
    "        df.columns = pd.MultiIndex.from_tuples(new_index)\n",
    "        return df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_results = get_results(get_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_binary_results = get_results(get_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-italy",
   "metadata": {},
   "source": [
    "### Final Results:\n",
    "\n",
    "\n",
    "\n",
    "#### All Three Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-convertible",
   "metadata": {},
   "source": [
    "#### Two Classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_binary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-bowling",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "Here is a summary of the hyperparameters use for each model.\n",
    "\n",
    "* Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logreg_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-priest",
   "metadata": {},
   "source": [
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-phrase",
   "metadata": {},
   "source": [
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-tension",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "### All Classes\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
