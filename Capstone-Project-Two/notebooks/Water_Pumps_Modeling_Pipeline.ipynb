{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "catholic-pharmacology",
   "metadata": {},
   "source": [
    "# Water Pumps - Modeling Pipeline\n",
    "\n",
    "In this notebook, I will take what I learned in the Modeling notebook to create a pipeline that fits all three models. The notebook can be configured to either over sample or under sample the data. For each model, hyperparameter tuning will be performed, using the strategy developed in the Modeling notebook. The best parameters will then be selected for the final model for each model type. All results are saved to a csv file. At the end of the notebook, the results between each model can be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-entry",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adapted-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-edwards",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "Set up configurations for current run of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = False\n",
    "debug = False\n",
    "sampling_type = 'over'\n",
    "# sampling_type = 'under'\n",
    "results_filename = 'pipeline_results.csv'\n",
    "if binary:\n",
    "    split_filename = results_filename.split('_')\n",
    "    results_filename = '_'.join([split_filename[0], 'binary', split_filename[1]])\n",
    "results_filepath = f'../results/{results_filename}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-murray",
   "metadata": {},
   "source": [
    "## Load Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coupled-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test():\n",
    "    file_list = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "    data_sets = []\n",
    "    for filename in file_list:\n",
    "        data_sets.append(pickle.load(open(f'../data/clean/{filename}', 'rb')))\n",
    "    return tuple(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opposed-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virtual-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this block to shortening training data for debugging.\n",
    "if debug:\n",
    "    row_cut = 100\n",
    "    X_train = X_train[:100]\n",
    "    y_train = y_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-conclusion",
   "metadata": {},
   "source": [
    "Load predictions from baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italian-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base = pickle.load(open(f'../data/clean/y_pred_base', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-scene",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alien-wallet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['functional', 'non functional'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.where(y_train == 'functional needs repair', 'non functional', y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mobile-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_train, X_test, y_train, y_test, sampling_type):\n",
    "    \n",
    "    if binary:\n",
    "        y_train = np.where(y_train == 'functional needs repair', 'non functional', y_train)\n",
    "        y_test = np.where(y_test == 'functional needs repair', 'non functional', y_test)\n",
    "    \n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_rescaled = scaler.transform(X_train)\n",
    "    X_test_pipe = scaler.transform(X_test)\n",
    "    \n",
    "    if sampling_type == 'over':\n",
    "        X_train_pipe, y_train_pipe = SMOTE().fit_resample(X_train_rescaled, y_train)\n",
    "    elif sampling_type == 'under':\n",
    "        X_train_pipe, y_train_pipe = RandomUnderSampler(random_state=42).fit_resample(X_train_rescaled, y_train)\n",
    "    else:\n",
    "        raise Exception(\"sampling_type must be 'over' or 'under'. Please try again.\")\n",
    "    \n",
    "    y_test_pipe = y_test\n",
    "    \n",
    "    return X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civil-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = prepare_data(X_train, X_test, y_train, y_test, sampling_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-nutrition",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-invitation",
   "metadata": {},
   "source": [
    "### Load Saved Results\n",
    "If a results file exists, load it, otherwise set it to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distributed-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(results_filepath):\n",
    "    df_results = pd.read_csv(results_filepath, index_col=0, header=[0, 1])\n",
    "else:\n",
    "    df_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wireless-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prepared-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(y_test, y_pred, model_type, df=None):\n",
    "    \n",
    "    if df is not None:\n",
    "        if model_type in df.columns:\n",
    "            df.drop(model_type, level=0, axis=1, inplace=True)\n",
    "    \n",
    "    results = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    df_results.drop(columns=['f1-score', 'support'], inplace=True)\n",
    "    df_results.drop(['accuracy', 'macro avg', 'weighted avg'], inplace=True)\n",
    "    \n",
    "    multi_columns = [(model_type, x) for x in df_results.columns]\n",
    "    df_results.columns = pd.MultiIndex.from_tuples(multi_columns)\n",
    "    \n",
    "    if df is None:\n",
    "        return df_results\n",
    "    else:\n",
    "        df_results = pd.concat([df, df_results], axis=1)\n",
    "        df_results.sort_index(axis=1, level=0, inplace=True)\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-drilling",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "Set up baseline model results and store in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cultural-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'base_line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "precious-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = store_results(y_test, y_pred_base, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "failing-flood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">base_line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.767559</td>\n",
       "      <td>0.911198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional needs repair</th>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.151938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non functional</th>\n",
       "      <td>0.787948</td>\n",
       "      <td>0.659432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        base_line          \n",
       "                        precision    recall\n",
       "functional               0.767559  0.911198\n",
       "functional needs repair  0.632258  0.151938\n",
       "non functional           0.787948  0.659432"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-julian",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wireless-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'logreg_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tired-editing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(max_iter=10000,\n",
       "                                                multi_class='multinomial',\n",
       "                                                solver='saga'),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'C': array([0.2, 0.6, 1. , 1.4, 1.8, 2.2]),\n",
       "                                        'penalty': ['l1', 'l2']},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_rs = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=10000)\n",
    "rs_logreg_params = {'C': np.arange(0.2, 2.4, 0.4), 'penalty': ['l1', 'l2']}\n",
    "rs_logreg = RandomizedSearchCV(logreg_rs, rs_logreg_params, random_state=42, n_jobs=-1)\n",
    "rs_logreg.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forty-algorithm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value for C is 2.200.\n",
      "The best penalty is l1.\n"
     ]
    }
   ],
   "source": [
    "best_C = rs_logreg.best_estimator_.get_params()['C']\n",
    "best_penalty = rs_logreg.best_estimator_.get_params()['penalty']\n",
    "print(f'The best value for C is {best_C:0.3f}.')\n",
    "print(f'The best penalty is {best_penalty}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "featured-bacteria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.2000000000000006, max_iter=10000,\n",
       "                   multi_class='multinomial', penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_best = LogisticRegression(solver='saga', multi_class='multinomial', C=best_C, penalty=best_penalty, max_iter=10000)\n",
    "logreg_best.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accredited-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg_best = logreg_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "parliamentary-surface",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_results = store_results(y_test, y_pred_logreg_best, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "further-charles",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">base_line</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_under</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.767559</td>\n",
       "      <td>0.911198</td>\n",
       "      <td>0.684826</td>\n",
       "      <td>0.580482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional needs repair</th>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.151938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non functional</th>\n",
       "      <td>0.787948</td>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.434357</td>\n",
       "      <td>0.636770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        base_line           logreg_under          \n",
       "                        precision    recall    precision    recall\n",
       "functional               0.767559  0.911198     0.684826  0.580482\n",
       "functional needs repair  0.632258  0.151938     0.000000  0.000000\n",
       "non functional           0.787948  0.659432     0.434357  0.636770"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-johnson",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "internal-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'rf_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "private-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs = RandomForestClassifier(random_state = 42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "endless-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = list(np.arange(10, 110, 10))\n",
    "max_depth_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "modified-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf_params = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': max_depth_list,\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': list(np.arange(1, 11, 1)),\n",
    "    'min_samples_split': list(np.arange(1, 11, 1)),\n",
    "    'n_estimators': list(np.arange(200, 2200, 200))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "distributed-bahrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10],\n",
       "                                        'min_samples_split': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf = RandomizedSearchCV(rf_rs, rs_rf_params, random_state=42, n_jobs=-1)\n",
    "rs_rf.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "novel-monkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters for random forest are:\n",
      "{'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 80, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print('The best hyperparameters for random forest are:')\n",
    "print(rs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "absent-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators = rs_rf.best_params_['n_estimators']*2,\n",
    "    min_samples_split = rs_rf.best_params_['min_samples_split'],\n",
    "    min_samples_leaf = rs_rf.best_params_['min_samples_leaf'],\n",
    "    max_features = rs_rf.best_params_['max_features'],\n",
    "    max_depth = rs_rf.best_params_['max_depth'],\n",
    "    bootstrap = rs_rf.best_params_['bootstrap'],\n",
    "    random_state = 42, \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "proprietary-classics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=80, max_features='sqrt',\n",
       "                       min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=2000, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dying-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "laughing-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_results = store_results(y_test, y_pred_rf, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "expanded-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">base_line</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_under</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.767559</td>\n",
       "      <td>0.911198</td>\n",
       "      <td>0.684826</td>\n",
       "      <td>0.580482</td>\n",
       "      <td>0.685298</td>\n",
       "      <td>0.632642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional needs repair</th>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.151938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non functional</th>\n",
       "      <td>0.787948</td>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.434357</td>\n",
       "      <td>0.636770</td>\n",
       "      <td>0.457150</td>\n",
       "      <td>0.611235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        base_line           logreg_under            rf_under  \\\n",
       "                        precision    recall    precision    recall precision   \n",
       "functional               0.767559  0.911198     0.684826  0.580482  0.685298   \n",
       "functional needs repair  0.632258  0.151938     0.000000  0.000000  0.000000   \n",
       "non functional           0.787948  0.659432     0.434357  0.636770  0.457150   \n",
       "\n",
       "                                   \n",
       "                           recall  \n",
       "functional               0.632642  \n",
       "functional needs repair  0.000000  \n",
       "non functional           0.611235  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-camping",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hollywood-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'xgb_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ordered-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    'functional': 0,\n",
    "    'functional needs repair': 1,\n",
    "    'non functional': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "negative-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = pd.Series(y_train_pipe).replace(class_mapping).values\n",
    "y_test_encoded = pd.Series(y_test_pipe).replace(class_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sapphire-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rs = XGBClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "developing-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs_params_xgb_over = {\n",
    "#     'max_depth': list(np.arange(1, 7, 2)),\n",
    "#     'min_child_weight': list(np.arange(1, 7, 2)),\n",
    "#     'gamma': [0, 1, 5]\n",
    "# }\n",
    "\n",
    "rs_params_xgb_over = {\n",
    "    'max_depth': list(np.arange(1)),\n",
    "    'min_child_weight': list(np.arange(1)),\n",
    "    'gamma': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "developmental-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:15:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=1000, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'gamma': [0], 'max_depth': [0],\n",
       "                                        'min_child_weight': [0]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb = RandomizedSearchCV(xgb_rs, rs_params_xgb_over, random_state=42, n_jobs=-1, n_iter=100)\n",
    "rs_xgb.fit(X_train_pipe, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "available-bargain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for XGBoost are:\n",
      "{'min_child_weight': 0, 'max_depth': 0, 'gamma': 0}\n"
     ]
    }
   ],
   "source": [
    "print('The best parameters for XGBoost are:')\n",
    "print(rs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "still-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=rs_xgb.best_params_['max_depth'],\n",
    "    min_child_weight=rs_xgb.best_params_['min_child_weight'],\n",
    "    gamma=rs_xgb.best_params_['gamma']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ignored-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:15:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=0,\n",
       "              min_child_weight=0, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best.fit(X_train_pipe, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "accurate-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = rf_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "tribal-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = {\n",
    "    0:'functional',\n",
    "    1:'functional needs repair',\n",
    "    2:'non functional'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "honest-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = pd.Series(y_pred_encoded).replace(reverse_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "breeding-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_results = store_results(y_test, y_pred_xgb, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "level-sixth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">base_line</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_under</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.767559</td>\n",
       "      <td>0.911198</td>\n",
       "      <td>0.684826</td>\n",
       "      <td>0.580482</td>\n",
       "      <td>0.685298</td>\n",
       "      <td>0.632642</td>\n",
       "      <td>0.685298</td>\n",
       "      <td>0.632642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional needs repair</th>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.151938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non functional</th>\n",
       "      <td>0.787948</td>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.434357</td>\n",
       "      <td>0.636770</td>\n",
       "      <td>0.457150</td>\n",
       "      <td>0.611235</td>\n",
       "      <td>0.457150</td>\n",
       "      <td>0.611235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        base_line           logreg_under            rf_under  \\\n",
       "                        precision    recall    precision    recall precision   \n",
       "functional               0.767559  0.911198     0.684826  0.580482  0.685298   \n",
       "functional needs repair  0.632258  0.151938     0.000000  0.000000  0.000000   \n",
       "non functional           0.787948  0.659432     0.434357  0.636770  0.457150   \n",
       "\n",
       "                                  xgb_under            \n",
       "                           recall precision    recall  \n",
       "functional               0.632642  0.685298  0.632642  \n",
       "functional needs repair  0.000000  0.000000  0.000000  \n",
       "non functional           0.611235  0.457150  0.611235  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-bangkok",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "Save the results from the pipeline to the results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "beautiful-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(results_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-intellectual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
