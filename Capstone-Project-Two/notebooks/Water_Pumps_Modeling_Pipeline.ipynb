{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "russian-russia",
   "metadata": {},
   "source": [
    "# Water Pumps - Modeling Pipeline\n",
    "\n",
    "**Plan:**\n",
    "1. Load training and testing data.\n",
    "2. Role resampling, encoding, and scaling into single function.\n",
    "3. Develop out each model.\n",
    "    1. Include hyperparameter tuning, saving best parameters.\n",
    "    2. Run model with best parameters.\n",
    "    3. Collect results from classification reports to a data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-paradise",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bright-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-polymer",
   "metadata": {},
   "source": [
    "## Load Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informed-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test():\n",
    "    file_list = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "    data_sets = []\n",
    "    for filename in file_list:\n",
    "        data_sets.append(pickle.load(open(f'../data/clean/{filename}', 'rb')))\n",
    "    return tuple(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "revolutionary-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-anthony",
   "metadata": {},
   "source": [
    "Load predictions from baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imperial-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_base = pickle.load(open(f'../data/clean/y_test_base', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-accounting",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "massive-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_train, X_test, y_train, y_test, sampling_type):\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_rescaled = scaler.transform(X_train)\n",
    "    X_test_pipe = scaler.transform(X_test)\n",
    "    \n",
    "    if sampling_type == 'over':\n",
    "        X_train_pipe, y_train_pipe = SMOTE().fit_resample(X_train_rescaled, y_train)\n",
    "    elif sampling_type == 'under':\n",
    "        X_train_pipe, y_train_pipe = RandomUnderSampler(random_state=42).fit_resample(X_train_rescaled, y_train)\n",
    "    else:\n",
    "        raise Exception(\"sampling_type must be 'over' or 'under'. Please try again.\")\n",
    "    \n",
    "    return X_train_pipe, X_test_pipe, y_train_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interested-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pipe, X_test_pipe, y_train_pipe = prepare_data(X_train, X_test, y_train, y_test, 'over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-nickel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
