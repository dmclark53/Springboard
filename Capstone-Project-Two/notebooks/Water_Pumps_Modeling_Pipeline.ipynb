{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forced-syria",
   "metadata": {},
   "source": [
    "# Water Pumps - Modeling Pipeline\n",
    "\n",
    "In this notebook, I will take what I learned in the Modeling notebook to create a pipeline that fits all three models. The notebook can be configured to either over sample or under sample the data. For each model, hyperparameter tuning will be performed, using the strategy developed in the Modeling notebook. The best parameters will then be selected for the final model for each model type. All results are saved to a csv file. At the end of the notebook, the results between each model can be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-meter",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "allied-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-theology",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "Set up configurations for current run of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "foreign-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = False\n",
    "debug = False\n",
    "sampling_type = 'over'\n",
    "# sampling_type = 'under'\n",
    "results_filename = 'pipeline_results.csv'\n",
    "if binary:\n",
    "    split_filename = results_filename.split('_')\n",
    "    results_filename = '_'.join([split_filename[0], 'binary', split_filename[1]])\n",
    "results_filepath = f'../results/{results_filename}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-graphic",
   "metadata": {},
   "source": [
    "## Load Train and Test Sets\n",
    "In order to ensure an equal comparison between the baseline model and the additional models developed here, the same training data as the baseline model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "responsible-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test():\n",
    "    file_list = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "    data_sets = []\n",
    "    for filename in file_list:\n",
    "        data_sets.append(pickle.load(open(f'../data/clean/{filename}', 'rb')))\n",
    "    return tuple(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "impaired-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "acquired-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this block to shortening training data for debugging.\n",
    "if debug:\n",
    "    row_cut = 100\n",
    "    X_train = X_train[:100]\n",
    "    y_train = y_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-bailey",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "Load predictions from baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "average-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base = pickle.load(open(f'../data/clean/y_pred_base', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-assessment",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "Data preparations includes:\n",
    "* Scaling the data to values between 0 and 1.\n",
    "* Resampling the data. Either:\n",
    "    * Over sampling.\n",
    "    * Under sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "vocal-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_train, X_test, y_train, y_test, sampling_type):\n",
    "    \n",
    "    if binary:\n",
    "        y_train = pd.Series(y_train).replace({'functional needs repair': 'faulty', 'non functional': 'faulty'}).values\n",
    "        y_test = pd.Series(y_test).replace({'functional needs repair': 'faulty', 'non functional': 'faulty'}).values\n",
    "    \n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_rescaled = scaler.transform(X_train)\n",
    "    X_test_pipe = scaler.transform(X_test)\n",
    "    \n",
    "    if sampling_type == 'over':\n",
    "        X_train_pipe, y_train_pipe = SMOTE().fit_resample(X_train_rescaled, y_train)\n",
    "    elif sampling_type == 'under':\n",
    "        X_train_pipe, y_train_pipe = RandomUnderSampler(random_state=42).fit_resample(X_train_rescaled, y_train)\n",
    "    else:\n",
    "        raise Exception(\"sampling_type must be 'over' or 'under'. Please try again.\")\n",
    "    \n",
    "    y_test_pipe = y_test\n",
    "    \n",
    "    return X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "italic-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = prepare_data(X_train, X_test, y_train, y_test, sampling_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-closer",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Here I will try three different models:\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-transaction",
   "metadata": {},
   "source": [
    "### Load Saved Results\n",
    "If a results file exists, load it, otherwise set it to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "interstate-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(results_filepath):\n",
    "    df_results = pd.read_csv(results_filepath, index_col=0, header=[0, 1])\n",
    "    df_results.drop('class count', level=1, axis=1, inplace=True)\n",
    "else:\n",
    "    df_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "analyzed-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">base_line</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_under</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.767559</td>\n",
       "      <td>0.911198</td>\n",
       "      <td>0.838948</td>\n",
       "      <td>0.637876</td>\n",
       "      <td>0.851116</td>\n",
       "      <td>0.648719</td>\n",
       "      <td>0.852985</td>\n",
       "      <td>0.646476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional needs repair</th>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.151938</td>\n",
       "      <td>0.218284</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>0.259851</td>\n",
       "      <td>0.756589</td>\n",
       "      <td>0.235776</td>\n",
       "      <td>0.758140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non functional</th>\n",
       "      <td>0.787948</td>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.717764</td>\n",
       "      <td>0.668050</td>\n",
       "      <td>0.715637</td>\n",
       "      <td>0.724545</td>\n",
       "      <td>0.737579</td>\n",
       "      <td>0.706033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        base_line           logreg_under            rf_under  \\\n",
       "                        precision    recall    precision    recall precision   \n",
       "functional               0.767559  0.911198     0.838948  0.637876  0.851116   \n",
       "functional needs repair  0.632258  0.151938     0.218284  0.725581  0.259851   \n",
       "non functional           0.787948  0.659432     0.717764  0.668050  0.715637   \n",
       "\n",
       "                                  xgb_under            \n",
       "                           recall precision    recall  \n",
       "functional               0.648719  0.852985  0.646476  \n",
       "functional needs repair  0.756589  0.235776  0.758140  \n",
       "non functional           0.724545  0.737579  0.706033  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "seventh-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(y_test, y_pred, model_type, df=None):\n",
    "    \n",
    "    if df is not None:\n",
    "        if model_type in df.columns:\n",
    "            df.drop(model_type, level=0, axis=1, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    results = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    df_results.drop(columns=['f1-score', 'support'], inplace=True)\n",
    "    df_results.drop(['accuracy', 'macro avg', 'weighted avg'], inplace=True)\n",
    "    \n",
    "    multi_columns = [(model_type, x) for x in df_results.columns]\n",
    "    df_results.columns = pd.MultiIndex.from_tuples(multi_columns)\n",
    "    \n",
    "    if df is None:\n",
    "        return df_results\n",
    "    else:\n",
    "        df_results = pd.concat([df, df_results], axis=1)\n",
    "        df_results.sort_index(axis=1, level=0, inplace=True)\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-julian",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "Set up baseline model results and store in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "assumed-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'base_line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "loose-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary == False:\n",
    "    df_results = store_results(y_test, y_pred_base, model_type, df=df_results)\n",
    "    df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-sunday",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "trained-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'logreg_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "initial-adult",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(max_iter=10000,\n",
       "                                                multi_class='multinomial',\n",
       "                                                solver='saga'),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'C': array([0.2, 0.6, 1. , 1.4, 1.8, 2.2]),\n",
       "                                        'penalty': ['l1', 'l2']},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_rs = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=10000)\n",
    "rs_logreg_params = {'C': np.arange(0.2, 2.4, 0.4), 'penalty': ['l1', 'l2']}\n",
    "rs_logreg = RandomizedSearchCV(logreg_rs, rs_logreg_params, random_state=42, n_jobs=-1)\n",
    "rs_logreg.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "stainless-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_params(best_params):\n",
    "    for key, value in best_params.items():\n",
    "        if type(best_params[key]) == str:\n",
    "            print(f' * {key}: {best_params[key]}')\n",
    "        else:\n",
    "            print(f' * {key}: {best_params[key]:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "synthetic-alberta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters of logistic regression are:\n",
      " * penalty: l1\n",
      " * C: 2.200\n"
     ]
    }
   ],
   "source": [
    "print('The best hyperparameters of logistic regression are:')\n",
    "print_best_params(rs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "greatest-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyper_params(model_type, sampling, binary, best_params):\n",
    "    \n",
    "    next_row = {\n",
    "        'sampling': sampling,\n",
    "        'num_classes': 3 - int(True == binary),\n",
    "    }\n",
    "    \n",
    "    for key, value in best_params.items():\n",
    "        next_row[key] = best_params[key]\n",
    "    \n",
    "    hyper_params_files = f'../results/{model_type}_hyperparams.csv'\n",
    "    if os.path.isfile(hyper_params_files):\n",
    "        df = pd.read_csv(hyper_params_files)\n",
    "        next_index = len(df)\n",
    "        df.loc[next_index] = next_row\n",
    "        df.drop_duplicates(subset=['sampling', 'num_classes'], ignore_index=True, inplace=True, keep='last')\n",
    "    else:\n",
    "        df = pd.DataFrame(next_row, index=[0])\n",
    "    df.to_csv(hyper_params_files, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "buried-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logreg_params = save_hyper_params('logreg', sampling_type, binary, rs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "tamil-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.2000000000000006, max_iter=10000,\n",
       "                   multi_class='multinomial', penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_best = LogisticRegression(\n",
    "    solver='saga', \n",
    "    multi_class='multinomial', \n",
    "    C=rs_logreg.best_params_['C'], \n",
    "    penalty=rs_logreg.best_params_['penalty'], \n",
    "    max_iter=10000\n",
    ")\n",
    "logreg_best.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "bacterial-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg_best = logreg_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "indie-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = store_results(y_test_pipe, y_pred_logreg_best, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-orlando",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "convinced-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'rf_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "constant-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs = RandomForestClassifier(random_state = 42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "hidden-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = list(np.arange(10, 110, 10))\n",
    "max_depth_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "disabled-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf_params = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': max_depth_list,\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': list(np.arange(1, 11, 1)),\n",
    "    'min_samples_split': list(np.arange(1, 11, 1)),\n",
    "    'n_estimators': list(np.arange(200, 2200, 200))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "funky-stock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10],\n",
       "                                        'min_samples_split': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf = RandomizedSearchCV(rf_rs, rs_rf_params, random_state=42, n_jobs=-1)\n",
    "rs_rf.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "laughing-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters for random forest are:\n",
      " * n_estimators: 800.000\n",
      " * min_samples_split: 3.000\n",
      " * min_samples_leaf: 1.000\n",
      " * max_features: auto\n",
      " * max_depth: 90.000\n",
      " * bootstrap: 1.000\n"
     ]
    }
   ],
   "source": [
    "print('The best hyperparameters for random forest are:')\n",
    "print_best_params(rs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-morgan",
   "metadata": {},
   "source": [
    "Double the number of trees for the final random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "desirable-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf.best_params_['n_estimators'] *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "electrical-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_params = save_hyper_params('rf', sampling_type, binary, rs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "monetary-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators = rs_rf.best_params_['n_estimators'],\n",
    "    min_samples_split = rs_rf.best_params_['min_samples_split'],\n",
    "    min_samples_leaf = rs_rf.best_params_['min_samples_leaf'],\n",
    "    max_features = rs_rf.best_params_['max_features'],\n",
    "    max_depth = rs_rf.best_params_['max_depth'],\n",
    "    bootstrap = rs_rf.best_params_['bootstrap'],\n",
    "    random_state = 42, \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "tight-determination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=90, min_samples_split=3, n_estimators=1600,\n",
       "                       n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.fit(X_train_pipe, y_train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "pressing-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "proper-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = store_results(y_test_pipe, y_pred_rf, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-regular",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "seventh-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = f'xgb_{sampling_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "neural-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary:\n",
    "    class_mapping = {\n",
    "        'functional': 0,\n",
    "        'faulty': 1\n",
    "    }\n",
    "else:\n",
    "    class_mapping = {\n",
    "        'functional': 0,\n",
    "        'functional needs repair': 1,\n",
    "        'non functional': 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "unlike-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = pd.Series(y_train_pipe).replace(class_mapping).values\n",
    "y_test_encoded = pd.Series(y_test_pipe).replace(class_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "ancient-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rs = XGBClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "dried-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    rs_params_xgb_over = {\n",
    "        'max_depth': [1],\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0]\n",
    "    }\n",
    "else:\n",
    "    rs_params_xgb_over = {\n",
    "        'max_depth': list(np.arange(1, 7, 2)),\n",
    "        'min_child_weight': list(np.arange(1, 7, 2)),\n",
    "        'gamma': [0, 1, 5]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "intermediate-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 27 is smaller than n_iter=100. Running 27 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:01:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=1000, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'gamma': [0, 1, 5],\n",
       "                                        'max_depth': [1, 3, 5],\n",
       "                                        'min_child_weight': [1, 3, 5]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb = RandomizedSearchCV(xgb_rs, rs_params_xgb_over, random_state=42, n_jobs=-1, n_iter=100)\n",
    "rs_xgb.fit(X_train_pipe, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "integral-chuck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for XGBoost are:\n",
      " * min_child_weight: 1.000\n",
      " * max_depth: 5.000\n",
      " * gamma: 0.000\n"
     ]
    }
   ],
   "source": [
    "print('The best parameters for XGBoost are:')\n",
    "print_best_params(rs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-dominant",
   "metadata": {},
   "source": [
    "A larger number of trees should improve performance. Set the total number of trees to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "cultural-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_xgb.best_params_['n_estimators'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "monthly-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_params = save_hyper_params('xgb', sampling_type, binary, rs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "defined-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = XGBClassifier(\n",
    "    n_estimators=rs_xgb.best_params_['n_estimators'],\n",
    "    max_depth=rs_xgb.best_params_['max_depth'],\n",
    "    min_child_weight=rs_xgb.best_params_['min_child_weight'],\n",
    "    gamma=rs_xgb.best_params_['gamma']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "collected-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/envs/springboard/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:03:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best.fit(X_train_pipe, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "atlantic-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = xgb_best.predict(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "eligible-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = {}\n",
    "if binary:\n",
    "    reverse_mapping = {\n",
    "        0:'functional',\n",
    "        1:'faulty'\n",
    "    }\n",
    "else:\n",
    "    reverse_mapping = {\n",
    "        0:'functional',\n",
    "        1:'functional needs repair',\n",
    "        2:'non functional'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "intended-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = pd.Series(y_pred_encoded).replace(reverse_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "liked-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = store_results(y_test_pipe, y_pred_xgb, model_type, df=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-blackjack",
   "metadata": {},
   "source": [
    "### Add Class Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "authorized-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_class_counts(df, y_test):\n",
    "    df_class_counts = pd.DataFrame(pd.Series(y_test).value_counts())\n",
    "    df_class_counts.columns = pd.MultiIndex.from_tuples([('', 'class count')])\n",
    "    df_results = pd.concat([df, df_class_counts], axis=1)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "opposite-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = add_class_counts(df_results, y_test_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-librarian",
   "metadata": {},
   "source": [
    "### Save Results\n",
    "Save the results from the pipeline to the results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "juvenile-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(results_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-testament",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "smart-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(get_binary=False):\n",
    "    results_filename = 'pipeline_results.csv'\n",
    "    if get_binary:\n",
    "        split_filename = results_filename.split('_')\n",
    "        results_filename = '_'.join([split_filename[0], 'binary', split_filename[1]])\n",
    "    results_filepath = f'../results/{results_filename}'\n",
    "    if os.path.isfile(results_filepath):\n",
    "        df = pd.read_csv(results_filepath, index_col=0, header=[0, 1])\n",
    "        unnnamed = [x[0] for x in df.columns if 'Unnamed' in x[0]][0]\n",
    "        new_index = [(x[0].replace(unnnamed, ' '), x[1]) if unnnamed in x else x for x in df.columns.values.tolist()]\n",
    "        df.columns = pd.MultiIndex.from_tuples(new_index)\n",
    "        return df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "annual-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_results = get_results(get_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "expensive-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_binary_results = get_results(get_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-africa",
   "metadata": {},
   "source": [
    "### Final Results:\n",
    "\n",
    "I carried out modeling to predict water pump functional status. The response variable consisted of three classes:\n",
    "* functional\n",
    "* functional needs repair\n",
    "* non functional\n",
    "\n",
    "Three different algorithms were tried:\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "* XGBoost\n",
    "\n",
    "All three models were compared to a baseline model. The baseline model used logistic regression with the no regularization.\n",
    "\n",
    "Each model was fit to the same test set. I used a train-test split of 30% test / 70% train. To improve model training speed, the train and test data were scaled to values between 0 and 1. As noted during preprosing, I observed a large class imbalance between each class. Therefore, I tried two resampling methods, over sampling and under sampling, to see if that improved the model performance.\n",
    "\n",
    "The goal of the modeling was to achieve a high recall score for the minority classes, which were the classes with faulty pumps.\n",
    "\n",
    "#### All Three Classes:\n",
    "I began with training each model to predict each of the three classes. In the below table I sumarise my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "sharp-diversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">base_line</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_under</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>class count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.767559</td>\n",
       "      <td>0.911198</td>\n",
       "      <td>0.845651</td>\n",
       "      <td>0.652458</td>\n",
       "      <td>0.838948</td>\n",
       "      <td>0.637876</td>\n",
       "      <td>0.834833</td>\n",
       "      <td>0.867452</td>\n",
       "      <td>0.851116</td>\n",
       "      <td>0.648719</td>\n",
       "      <td>0.825182</td>\n",
       "      <td>0.867452</td>\n",
       "      <td>0.852985</td>\n",
       "      <td>0.646476</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional needs repair</th>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.151938</td>\n",
       "      <td>0.225578</td>\n",
       "      <td>0.741085</td>\n",
       "      <td>0.218284</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>0.466899</td>\n",
       "      <td>0.415504</td>\n",
       "      <td>0.259851</td>\n",
       "      <td>0.756589</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.235776</td>\n",
       "      <td>0.758140</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non functional</th>\n",
       "      <td>0.787948</td>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.733426</td>\n",
       "      <td>0.674433</td>\n",
       "      <td>0.717764</td>\n",
       "      <td>0.668050</td>\n",
       "      <td>0.813356</td>\n",
       "      <td>0.777530</td>\n",
       "      <td>0.715637</td>\n",
       "      <td>0.724545</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.759336</td>\n",
       "      <td>0.737579</td>\n",
       "      <td>0.706033</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        base_line           logreg_over            \\\n",
       "                        precision    recall   precision    recall   \n",
       "functional               0.767559  0.911198    0.845651  0.652458   \n",
       "functional needs repair  0.632258  0.151938    0.225578  0.741085   \n",
       "non functional           0.787948  0.659432    0.733426  0.674433   \n",
       "\n",
       "                        logreg_under             rf_over            rf_under  \\\n",
       "                           precision    recall precision    recall precision   \n",
       "functional                  0.838948  0.637876  0.834833  0.867452  0.851116   \n",
       "functional needs repair     0.218284  0.725581  0.466899  0.415504  0.259851   \n",
       "non functional              0.717764  0.668050  0.813356  0.777530  0.715637   \n",
       "\n",
       "                                   xgb_over           xgb_under            \\\n",
       "                           recall precision    recall precision    recall   \n",
       "functional               0.648719  0.825182  0.867452  0.852985  0.646476   \n",
       "functional needs repair  0.756589  0.462963  0.387597  0.235776  0.758140   \n",
       "non functional           0.724545  0.802632  0.759336  0.737579  0.706033   \n",
       "\n",
       "                                     \n",
       "                        class count  \n",
       "functional                     5349  \n",
       "functional needs repair         645  \n",
       "non functional                 3133  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-personal",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* All three models perform better in recall as compared to the baseline model.\n",
    "* The best model was created using XGBoost with undersampling.\n",
    "    * The highest recall score was 0.76.\n",
    "\n",
    "While the models did perform better than the baseline model, a recall score of 0.76 is still pretty low. So, I tried modeling the data again using two classes.\n",
    "\n",
    "##### Hyperparameters\n",
    "Here are the hyperparameters that were used for each model:\n",
    "\n",
    "* Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "racial-concert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>3</td>\n",
       "      <td>l2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over</td>\n",
       "      <td>3</td>\n",
       "      <td>l1</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sampling  num_classes penalty    C\n",
       "0    under            3      l2  2.2\n",
       "1     over            3      l1  2.2"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logreg_params[df_logreg_params['num_classes'] == 3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-pontiac",
   "metadata": {},
   "source": [
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "latin-being",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bootstrap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>3</td>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over</td>\n",
       "      <td>3</td>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sampling  num_classes  n_estimators  min_samples_split  min_samples_leaf  \\\n",
       "0    under            3          1600                  3                 1   \n",
       "1     over            3          1600                  3                 1   \n",
       "\n",
       "  max_features  max_depth  bootstrap  \n",
       "0         auto         90       True  \n",
       "1         auto         90       True  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_params[df_rf_params['num_classes'] == 3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-vegetation",
   "metadata": {},
   "source": [
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "sorted-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sampling  num_classes  min_child_weight  max_depth  gamma  n_estimators\n",
       "0    under            3                 1          5      1          1000\n",
       "1     over            3                 1          5      0          1000"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb_params[df_xgb_params['num_classes'] == 3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-powell",
   "metadata": {},
   "source": [
    "#### Two Classes:\n",
    "I combined the minority classes _functional needs repair_ and _non functional_ into a single class called _faulty_. The goal now was simplified to identify good and problematic.\n",
    "\n",
    "Here are the results of the binary classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "vocal-remove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">logreg_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rf_under</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_over</th>\n",
       "      <th colspan=\"2\" halign=\"left\">xgb_under</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>class count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>faulty</th>\n",
       "      <td>0.731618</td>\n",
       "      <td>0.737427</td>\n",
       "      <td>0.727178</td>\n",
       "      <td>0.742192</td>\n",
       "      <td>0.805525</td>\n",
       "      <td>0.764161</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>0.798571</td>\n",
       "      <td>0.794540</td>\n",
       "      <td>0.747221</td>\n",
       "      <td>0.752093</td>\n",
       "      <td>0.784542</td>\n",
       "      <td>3778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.813499</td>\n",
       "      <td>0.808936</td>\n",
       "      <td>0.815215</td>\n",
       "      <td>0.803328</td>\n",
       "      <td>0.839257</td>\n",
       "      <td>0.869695</td>\n",
       "      <td>0.853146</td>\n",
       "      <td>0.826510</td>\n",
       "      <td>0.828669</td>\n",
       "      <td>0.863526</td>\n",
       "      <td>0.843039</td>\n",
       "      <td>0.817349</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logreg_over           logreg_under             rf_over            \\\n",
       "             precision    recall    precision    recall precision    recall   \n",
       "faulty        0.731618  0.737427     0.727178  0.742192  0.805525  0.764161   \n",
       "functional    0.813499  0.808936     0.815215  0.803328  0.839257  0.869695   \n",
       "\n",
       "            rf_under            xgb_over           xgb_under            \\\n",
       "           precision    recall precision    recall precision    recall   \n",
       "faulty      0.764766  0.798571  0.794540  0.747221  0.752093  0.784542   \n",
       "functional  0.853146  0.826510  0.828669  0.863526  0.843039  0.817349   \n",
       "\n",
       "                        \n",
       "           class count  \n",
       "faulty            3778  \n",
       "functional        5349  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_binary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-longer",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* The best model was random forest, using undersampling.\n",
    "    * The highest recall value was 0.80.\n",
    "\n",
    "#### Hyperparameters\n",
    "This is a summary of the hyperparameters use for each binary classification model.\n",
    "\n",
    "* Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "brief-vanilla",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>2</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over</td>\n",
       "      <td>2</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sampling  num_classes penalty    C\n",
       "0    under            2      l2  1.8\n",
       "1     over            2      l1  1.0"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logreg_params[df_logreg_params['num_classes'] == 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-melbourne",
   "metadata": {},
   "source": [
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "developed-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bootstrap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>2</td>\n",
       "      <td>3600</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sampling  num_classes  n_estimators  min_samples_split  min_samples_leaf  \\\n",
       "0    under            2          3600                  6                 2   \n",
       "1     over            2          1600                  3                 1   \n",
       "\n",
       "  max_features  max_depth  bootstrap  \n",
       "0         auto         90      False  \n",
       "1         auto         90       True  "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_params[df_rf_params['num_classes'] == 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-adobe",
   "metadata": {},
   "source": [
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "embedded-suicide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sampling  num_classes  min_child_weight  max_depth  gamma  n_estimators\n",
       "0    under            2                 1          3      0          1000\n",
       "1     over            2                 1          5      0          1000"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb_params[df_xgb_params['num_classes'] == 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-provider",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "I was able to achieve a recall score of 0.80 on the minority class (_faulty_). The best algorithm was random forest, using an under sampled training set to balance the classes. Also, the two minority classes, _non functional_ and _functional needs repair_ were combined into a single class, _faulty_.\n",
    "\n",
    "## Recommendation to Client\n",
    "I have created a model that can accurately identify faulty pumps. By optimizing on recall, I chose to reduce the error of predicting a pump is _functional_, when in fact it is _faulty_. I believe this model can be an accurate tool for the Tanzanian government in there effort to monitor pump status in the country. It should greatly reduce the need to determine the pump status in person and can instead rely on pump data collected on line. \n",
    "\n",
    "## Future Directions\n",
    "While I have achieved an acceptable model for the Tanzanian government, there are a few areas I would like to improve on during updated versions of the project. This includes:\n",
    "* Try additional sampling methods to counter class imbalance, aside from the two I tried here.\n",
    "* Perform a more detailed exploration of hyperparameter values. A more granualar search could lead to more refined models with better results.\n",
    "* Try a different train/test split. A smaller split could give the models more data to train on, which could possibly improve the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-allen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
